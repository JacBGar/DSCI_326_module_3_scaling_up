{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with multiple files\n",
    "\n",
    "On occasion, we will need to combine more than 2 files using some combination of `UNION` and `JOIN`.  In this lecture, we will show a clean approach to scaling up these operations up to any number of files.  In the process, we will\n",
    "\n",
    "1. Use `list` comprehensions to process and `UNION` many similar files.\n",
    "2. Use `dict` comprehensions to store and access many tables by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import polars as pl\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basics of working with many files.\n",
    "\n",
    "* Use `glob.glob` to find all files that match a pattern\n",
    "* Convert all files to `pd.DataFrames`\n",
    "* Store the `df` in a list or dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the heck is a `glob`\n",
    "\n",
    "`glob.glob`\n",
    "\n",
    "* Takes a path regular expression\n",
    "* Returns a list of files that match the patterm\n",
    "* Relative paths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/auto_sales_apr.csv', './data/auto_sales_may.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_files = glob('./data/auto_sales_*.csv')\n",
    "sales_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search tools for `glob`\n",
    "\n",
    "* Use `*` as a wildcard,\n",
    "* Use `?` for optional characters, and\n",
    "* Use `[...]` to define character classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/baseballdatabank-2023.1/core/Managers.csv',\n",
       " './data/baseballdatabank-2023.1/core/Fielding.csv',\n",
       " './data/baseballdatabank-2023.1/core/Parks.csv',\n",
       " './data/baseballdatabank-2023.1/core/People.csv',\n",
       " './data/baseballdatabank-2023.1/core/PitchingPost.csv',\n",
       " './data/baseballdatabank-2023.1/core/Teams.csv',\n",
       " './data/baseballdatabank-2023.1/core/Appearances.csv',\n",
       " './data/baseballdatabank-2023.1/core/TeamsFranchises.csv',\n",
       " './data/baseballdatabank-2023.1/core/Batting.csv',\n",
       " './data/baseballdatabank-2023.1/core/ManagersHalf.csv',\n",
       " './data/baseballdatabank-2023.1/core/FieldingOF.csv',\n",
       " './data/baseballdatabank-2023.1/core/Pitching.csv',\n",
       " './data/baseballdatabank-2023.1/core/HomeGames.csv',\n",
       " './data/baseballdatabank-2023.1/core/BattingPost.csv',\n",
       " './data/baseballdatabank-2023.1/core/TeamsHalf.csv',\n",
       " './data/baseballdatabank-2023.1/core/SeriesPost.csv',\n",
       " './data/baseballdatabank-2023.1/core/FieldingPost.csv',\n",
       " './data/baseballdatabank-2023.1/core/AllstarFull.csv',\n",
       " './data/baseballdatabank-2023.1/core/FieldingOFsplit.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(baseball_core_csv := \n",
    " glob('./data/baseballdatabank*/core/*csv', recursive=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive search with `glob`\n",
    "\n",
    "To search all folders and sub-folders, you need to\n",
    "1. Set the `recursive=True` option in `glob`, and\n",
    "2. Use `**` to represent one or more folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/baseballdatabank-2023.1/core/Managers.csv',\n",
       " './data/baseballdatabank-2023.1/core/Fielding.csv',\n",
       " './data/baseballdatabank-2023.1/core/Parks.csv',\n",
       " './data/baseballdatabank-2023.1/core/People.csv',\n",
       " './data/baseballdatabank-2023.1/core/PitchingPost.csv',\n",
       " './data/baseballdatabank-2023.1/core/Teams.csv',\n",
       " './data/baseballdatabank-2023.1/core/Appearances.csv',\n",
       " './data/baseballdatabank-2023.1/core/TeamsFranchises.csv',\n",
       " './data/baseballdatabank-2023.1/core/Batting.csv',\n",
       " './data/baseballdatabank-2023.1/core/ManagersHalf.csv',\n",
       " './data/baseballdatabank-2023.1/core/FieldingOF.csv',\n",
       " './data/baseballdatabank-2023.1/core/Pitching.csv',\n",
       " './data/baseballdatabank-2023.1/core/HomeGames.csv',\n",
       " './data/baseballdatabank-2023.1/core/BattingPost.csv',\n",
       " './data/baseballdatabank-2023.1/core/TeamsHalf.csv',\n",
       " './data/baseballdatabank-2023.1/core/SeriesPost.csv',\n",
       " './data/baseballdatabank-2023.1/core/FieldingPost.csv',\n",
       " './data/baseballdatabank-2023.1/core/AllstarFull.csv',\n",
       " './data/baseballdatabank-2023.1/core/FieldingOFsplit.csv',\n",
       " './data/baseballdatabank-2023.1/contrib/AwardsManagers.csv',\n",
       " './data/baseballdatabank-2023.1/contrib/AwardsPlayers.csv',\n",
       " './data/baseballdatabank-2023.1/contrib/Salaries.csv',\n",
       " './data/baseballdatabank-2023.1/contrib/Schools.csv',\n",
       " './data/baseballdatabank-2023.1/contrib/AwardsSharePlayers.csv',\n",
       " './data/baseballdatabank-2023.1/contrib/CollegePlaying.csv',\n",
       " './data/baseballdatabank-2023.1/contrib/HallOfFame.csv',\n",
       " './data/baseballdatabank-2023.1/contrib/AwardsShareManagers.csv',\n",
       " './data/baseballdatabank-2023.1/upstream/Teams.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_baseball_csv \n",
    " := glob('./data/baseballdatabank*/**/*.csv', recursive=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information from a `glob` search result.\n",
    "\n",
    "**Options.**\n",
    "1. Use string methods such as `split`, or\n",
    "2. Use a regular expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1 - Using the `str.split` method to extract a file name.\n",
    "\n",
    "**Note.** The following cells are meant to show how the solution evolves.  In practice, this would all be proto-typed in a single cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.', 'data', 'baseballdatabank-2023.1', 'core', 'Managers.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'Fielding.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'Parks.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'People.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'PitchingPost.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'Teams.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'Appearances.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'TeamsFranchises.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'Batting.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'ManagersHalf.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'FieldingOF.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'Pitching.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'HomeGames.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'BattingPost.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'TeamsHalf.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'SeriesPost.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'FieldingPost.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'AllstarFull.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'core', 'FieldingOFsplit.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'contrib', 'AwardsManagers.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'contrib', 'AwardsPlayers.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'contrib', 'Salaries.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'contrib', 'Schools.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'contrib', 'AwardsSharePlayers.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'contrib', 'CollegePlaying.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'contrib', 'HallOfFame.csv'],\n",
       " ['.',\n",
       "  'data',\n",
       "  'baseballdatabank-2023.1',\n",
       "  'contrib',\n",
       "  'AwardsShareManagers.csv'],\n",
       " ['.', 'data', 'baseballdatabank-2023.1', 'upstream', 'Teams.csv']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Split on forward slash\n",
    "[p.split('/') for p in all_baseball_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Managers.csv',\n",
       " 'Fielding.csv',\n",
       " 'Parks.csv',\n",
       " 'People.csv',\n",
       " 'PitchingPost.csv',\n",
       " 'Teams.csv',\n",
       " 'Appearances.csv',\n",
       " 'TeamsFranchises.csv',\n",
       " 'Batting.csv',\n",
       " 'ManagersHalf.csv',\n",
       " 'FieldingOF.csv',\n",
       " 'Pitching.csv',\n",
       " 'HomeGames.csv',\n",
       " 'BattingPost.csv',\n",
       " 'TeamsHalf.csv',\n",
       " 'SeriesPost.csv',\n",
       " 'FieldingPost.csv',\n",
       " 'AllstarFull.csv',\n",
       " 'FieldingOFsplit.csv',\n",
       " 'AwardsManagers.csv',\n",
       " 'AwardsPlayers.csv',\n",
       " 'Salaries.csv',\n",
       " 'Schools.csv',\n",
       " 'AwardsSharePlayers.csv',\n",
       " 'CollegePlaying.csv',\n",
       " 'HallOfFame.csv',\n",
       " 'AwardsShareManagers.csv',\n",
       " 'Teams.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Split on forward slash\n",
    "# 2. Get the last element \n",
    "[p.split('/')[-1] for p in all_baseball_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Managers', 'csv'],\n",
       " ['Fielding', 'csv'],\n",
       " ['Parks', 'csv'],\n",
       " ['People', 'csv'],\n",
       " ['PitchingPost', 'csv'],\n",
       " ['Teams', 'csv'],\n",
       " ['Appearances', 'csv'],\n",
       " ['TeamsFranchises', 'csv'],\n",
       " ['Batting', 'csv'],\n",
       " ['ManagersHalf', 'csv'],\n",
       " ['FieldingOF', 'csv'],\n",
       " ['Pitching', 'csv'],\n",
       " ['HomeGames', 'csv'],\n",
       " ['BattingPost', 'csv'],\n",
       " ['TeamsHalf', 'csv'],\n",
       " ['SeriesPost', 'csv'],\n",
       " ['FieldingPost', 'csv'],\n",
       " ['AllstarFull', 'csv'],\n",
       " ['FieldingOFsplit', 'csv'],\n",
       " ['AwardsManagers', 'csv'],\n",
       " ['AwardsPlayers', 'csv'],\n",
       " ['Salaries', 'csv'],\n",
       " ['Schools', 'csv'],\n",
       " ['AwardsSharePlayers', 'csv'],\n",
       " ['CollegePlaying', 'csv'],\n",
       " ['HallOfFame', 'csv'],\n",
       " ['AwardsShareManagers', 'csv'],\n",
       " ['Teams', 'csv']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Split on forward slash\n",
    "# 2. Get the last element \n",
    "# 3. Split off the file type \n",
    "[p.split('/')[-1].split('.') for p in all_baseball_csv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Managers',\n",
       " 'Fielding',\n",
       " 'Parks',\n",
       " 'People',\n",
       " 'PitchingPost',\n",
       " 'Teams',\n",
       " 'Appearances',\n",
       " 'TeamsFranchises',\n",
       " 'Batting',\n",
       " 'ManagersHalf',\n",
       " 'FieldingOF',\n",
       " 'Pitching',\n",
       " 'HomeGames',\n",
       " 'BattingPost',\n",
       " 'TeamsHalf',\n",
       " 'SeriesPost',\n",
       " 'FieldingPost',\n",
       " 'AllstarFull',\n",
       " 'FieldingOFsplit',\n",
       " 'AwardsManagers',\n",
       " 'AwardsPlayers',\n",
       " 'Salaries',\n",
       " 'Schools',\n",
       " 'AwardsSharePlayers',\n",
       " 'CollegePlaying',\n",
       " 'HallOfFame',\n",
       " 'AwardsShareManagers',\n",
       " 'Teams']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Split on forward slash\n",
    "# 2. Get the last element \n",
    "# 3. Split off the file type \n",
    "# 4. Get the first enter (e.g. file name)\n",
    "[p.split('/')[-1].split('.')[0] for p in all_baseball_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Managers',\n",
       " 'Fielding',\n",
       " 'Parks',\n",
       " 'People',\n",
       " 'PitchingPost',\n",
       " 'Teams',\n",
       " 'Appearances',\n",
       " 'TeamsFranchises',\n",
       " 'Batting',\n",
       " 'ManagersHalf',\n",
       " 'FieldingOF',\n",
       " 'Pitching',\n",
       " 'HomeGames',\n",
       " 'BattingPost',\n",
       " 'TeamsHalf',\n",
       " 'SeriesPost',\n",
       " 'FieldingPost',\n",
       " 'AllstarFull',\n",
       " 'FieldingOFsplit',\n",
       " 'AwardsManagers',\n",
       " 'AwardsPlayers',\n",
       " 'Salaries',\n",
       " 'Schools',\n",
       " 'AwardsSharePlayers',\n",
       " 'CollegePlaying',\n",
       " 'HallOfFame',\n",
       " 'AwardsShareManagers',\n",
       " 'Teams']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Split on forward slash\n",
    "# 2. Get the last element \n",
    "# 3. Split off the file type \n",
    "# 4. Get the first enter (e.g. file name)\n",
    "# 5. Refactor\n",
    "get_file_name = lambda p: p.split('/')[-1].split('.')[0]\n",
    "\n",
    "[get_file_name(p) for p in all_baseball_csv]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2 - Using a regular expression to capture the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(0, 48), match='./data/baseballdatabank-2023.1/core/Managers.csv'>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Start with an example path\n",
    "file_name = re.compile(r'./data/baseballdatabank-2023.1/core/Managers.csv')\n",
    "\n",
    "[_match for p in all_baseball_csv if (_match := file_name.match(p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(0, 48), match='./data/baseballdatabank-2023.1/core/Managers.csv'>,\n",
       " <re.Match object; span=(0, 48), match='./data/baseballdatabank-2023.1/core/Fielding.csv'>,\n",
       " <re.Match object; span=(0, 45), match='./data/baseballdatabank-2023.1/core/Parks.csv'>,\n",
       " <re.Match object; span=(0, 46), match='./data/baseballdatabank-2023.1/core/People.csv'>,\n",
       " <re.Match object; span=(0, 52), match='./data/baseballdatabank-2023.1/core/PitchingPost.>,\n",
       " <re.Match object; span=(0, 45), match='./data/baseballdatabank-2023.1/core/Teams.csv'>,\n",
       " <re.Match object; span=(0, 51), match='./data/baseballdatabank-2023.1/core/Appearances.c>,\n",
       " <re.Match object; span=(0, 55), match='./data/baseballdatabank-2023.1/core/TeamsFranchis>,\n",
       " <re.Match object; span=(0, 47), match='./data/baseballdatabank-2023.1/core/Batting.csv'>,\n",
       " <re.Match object; span=(0, 52), match='./data/baseballdatabank-2023.1/core/ManagersHalf.>,\n",
       " <re.Match object; span=(0, 50), match='./data/baseballdatabank-2023.1/core/FieldingOF.cs>,\n",
       " <re.Match object; span=(0, 48), match='./data/baseballdatabank-2023.1/core/Pitching.csv'>,\n",
       " <re.Match object; span=(0, 49), match='./data/baseballdatabank-2023.1/core/HomeGames.csv>,\n",
       " <re.Match object; span=(0, 51), match='./data/baseballdatabank-2023.1/core/BattingPost.c>,\n",
       " <re.Match object; span=(0, 49), match='./data/baseballdatabank-2023.1/core/TeamsHalf.csv>,\n",
       " <re.Match object; span=(0, 50), match='./data/baseballdatabank-2023.1/core/SeriesPost.cs>,\n",
       " <re.Match object; span=(0, 52), match='./data/baseballdatabank-2023.1/core/FieldingPost.>,\n",
       " <re.Match object; span=(0, 51), match='./data/baseballdatabank-2023.1/core/AllstarFull.c>,\n",
       " <re.Match object; span=(0, 55), match='./data/baseballdatabank-2023.1/core/FieldingOFspl>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Start with an example path\n",
    "# 2. Make it match any file name\n",
    "\n",
    "file_name = re.compile(r'./data/baseballdatabank-2023.1/core/[a-zA-Z]+.csv')\n",
    "\n",
    "[_match for p in all_baseball_csv if (_match := file_name.match(p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(0, 48), match='./data/baseballdatabank-2023.1/core/Managers.csv'>,\n",
       " <re.Match object; span=(0, 48), match='./data/baseballdatabank-2023.1/core/Fielding.csv'>,\n",
       " <re.Match object; span=(0, 45), match='./data/baseballdatabank-2023.1/core/Parks.csv'>,\n",
       " <re.Match object; span=(0, 46), match='./data/baseballdatabank-2023.1/core/People.csv'>,\n",
       " <re.Match object; span=(0, 52), match='./data/baseballdatabank-2023.1/core/PitchingPost.>,\n",
       " <re.Match object; span=(0, 45), match='./data/baseballdatabank-2023.1/core/Teams.csv'>,\n",
       " <re.Match object; span=(0, 51), match='./data/baseballdatabank-2023.1/core/Appearances.c>,\n",
       " <re.Match object; span=(0, 55), match='./data/baseballdatabank-2023.1/core/TeamsFranchis>,\n",
       " <re.Match object; span=(0, 47), match='./data/baseballdatabank-2023.1/core/Batting.csv'>,\n",
       " <re.Match object; span=(0, 52), match='./data/baseballdatabank-2023.1/core/ManagersHalf.>,\n",
       " <re.Match object; span=(0, 50), match='./data/baseballdatabank-2023.1/core/FieldingOF.cs>,\n",
       " <re.Match object; span=(0, 48), match='./data/baseballdatabank-2023.1/core/Pitching.csv'>,\n",
       " <re.Match object; span=(0, 49), match='./data/baseballdatabank-2023.1/core/HomeGames.csv>,\n",
       " <re.Match object; span=(0, 51), match='./data/baseballdatabank-2023.1/core/BattingPost.c>,\n",
       " <re.Match object; span=(0, 49), match='./data/baseballdatabank-2023.1/core/TeamsHalf.csv>,\n",
       " <re.Match object; span=(0, 50), match='./data/baseballdatabank-2023.1/core/SeriesPost.cs>,\n",
       " <re.Match object; span=(0, 52), match='./data/baseballdatabank-2023.1/core/FieldingPost.>,\n",
       " <re.Match object; span=(0, 51), match='./data/baseballdatabank-2023.1/core/AllstarFull.c>,\n",
       " <re.Match object; span=(0, 55), match='./data/baseballdatabank-2023.1/core/FieldingOFspl>,\n",
       " <re.Match object; span=(0, 57), match='./data/baseballdatabank-2023.1/contrib/AwardsMana>,\n",
       " <re.Match object; span=(0, 56), match='./data/baseballdatabank-2023.1/contrib/AwardsPlay>,\n",
       " <re.Match object; span=(0, 51), match='./data/baseballdatabank-2023.1/contrib/Salaries.c>,\n",
       " <re.Match object; span=(0, 50), match='./data/baseballdatabank-2023.1/contrib/Schools.cs>,\n",
       " <re.Match object; span=(0, 61), match='./data/baseballdatabank-2023.1/contrib/AwardsShar>,\n",
       " <re.Match object; span=(0, 57), match='./data/baseballdatabank-2023.1/contrib/CollegePla>,\n",
       " <re.Match object; span=(0, 53), match='./data/baseballdatabank-2023.1/contrib/HallOfFame>,\n",
       " <re.Match object; span=(0, 62), match='./data/baseballdatabank-2023.1/contrib/AwardsShar>,\n",
       " <re.Match object; span=(0, 49), match='./data/baseballdatabank-2023.1/upstream/Teams.csv>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Start with an example path\n",
    "# 2. Make it match any file name\n",
    "# 3. Make it match any subfolder\n",
    "\n",
    "file_name = re.compile(r'./data/baseballdatabank-2023.1/[a-z]+/[a-zA-Z]+.csv')\n",
    "\n",
    "[_match for p in all_baseball_csv if (_match := file_name.match(p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Managers',\n",
       " 'Fielding',\n",
       " 'Parks',\n",
       " 'People',\n",
       " 'PitchingPost',\n",
       " 'Teams',\n",
       " 'Appearances',\n",
       " 'TeamsFranchises',\n",
       " 'Batting',\n",
       " 'ManagersHalf',\n",
       " 'FieldingOF',\n",
       " 'Pitching',\n",
       " 'HomeGames',\n",
       " 'BattingPost',\n",
       " 'TeamsHalf',\n",
       " 'SeriesPost',\n",
       " 'FieldingPost',\n",
       " 'AllstarFull',\n",
       " 'FieldingOFsplit',\n",
       " 'AwardsManagers',\n",
       " 'AwardsPlayers',\n",
       " 'Salaries',\n",
       " 'Schools',\n",
       " 'AwardsSharePlayers',\n",
       " 'CollegePlaying',\n",
       " 'HallOfFame',\n",
       " 'AwardsShareManagers',\n",
       " 'Teams']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Start with an example path\n",
    "# 2. Make it match any file name\n",
    "# 3. Make it match any subfolder\n",
    "# 4. Add a capture group and extract the data\n",
    "\n",
    "file_name = re.compile(r'./data/baseballdatabank-2023.1/[a-z]+/([a-zA-Z]+).csv')\n",
    "\n",
    "[_match.group(1) for p in all_baseball_csv if (_match := file_name.match(p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Managers',\n",
       " 'Fielding',\n",
       " 'Parks',\n",
       " 'People',\n",
       " 'PitchingPost',\n",
       " 'Teams',\n",
       " 'Appearances',\n",
       " 'TeamsFranchises',\n",
       " 'Batting',\n",
       " 'ManagersHalf',\n",
       " 'FieldingOF',\n",
       " 'Pitching',\n",
       " 'HomeGames',\n",
       " 'BattingPost',\n",
       " 'TeamsHalf',\n",
       " 'SeriesPost',\n",
       " 'FieldingPost',\n",
       " 'AllstarFull',\n",
       " 'FieldingOFsplit',\n",
       " 'AwardsManagers',\n",
       " 'AwardsPlayers',\n",
       " 'Salaries',\n",
       " 'Schools',\n",
       " 'AwardsSharePlayers',\n",
       " 'CollegePlaying',\n",
       " 'HallOfFame',\n",
       " 'AwardsShareManagers',\n",
       " 'Teams']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Start with an example path\n",
    "# 2. Make it match any file name\n",
    "# 3. Make it match any subfolder\n",
    "# 4. Add a capture group and extract the data\n",
    "# 5. Refactor\n",
    "\n",
    "file_name = re.compile(r'./data/baseballdatabank-2023.1/[a-z]+/([a-zA-Z]+).csv')\n",
    "\n",
    "get_file_names = lambda paths: [_match.group(1) for p in paths if (_match := file_name.match(p))]\n",
    "\n",
    "get_file_names(all_baseball_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Windows paths\n",
    "\n",
    "* Windows uses backslash `\\` instead of forward slash `/` to separate folders/files.\n",
    "* Even on Windows, `glob` understands unix style paths that use `/` to separate files/folders.\n",
    "* Since `\\` is the escape character in Python, Windows paths will contain an escaped/literal backslash `\\\\`.\n",
    "* The wild card parts of the pattern will return Windows style paths with `\\\\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data\\\\baseballdatabank-2023.1\\\\core\\\\AllstarFull.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Appearances.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Batting.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\BattingPost.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Fielding.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\FieldingOF.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\FieldingOFsplit.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\FieldingPost.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\HomeGames.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Managers.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\ManagersHalf.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Parks.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\People.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Pitching.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\PitchingPost.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\SeriesPost.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Teams.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\TeamsFranchises.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\TeamsHalf.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-recursive search run on Windows\n",
    "baseball_core_csv = glob('./data/baseballdatabank*/core/*csv', recursive=True)\n",
    "\n",
    "baseball_core_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data\\\\baseballdatabank-2023.1\\\\contrib\\\\AwardsManagers.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\contrib\\\\AwardsPlayers.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\contrib\\\\AwardsShareManagers.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\contrib\\\\AwardsSharePlayers.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\contrib\\\\CollegePlaying.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\contrib\\\\HallOfFame.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\contrib\\\\Salaries.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\contrib\\\\Schools.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\AllstarFull.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Appearances.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Batting.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\BattingPost.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Fielding.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\FieldingOF.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\FieldingOFsplit.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\FieldingPost.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\HomeGames.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Managers.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\ManagersHalf.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Parks.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\People.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Pitching.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\PitchingPost.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\SeriesPost.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\Teams.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\TeamsFranchises.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\core\\\\TeamsHalf.csv',\n",
       " './data\\\\baseballdatabank-2023.1\\\\upstream\\\\Teams.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recursive search run on Windows\n",
    "all_baseball_csv = glob('./data/baseballdatabank*/**/*.csv', recursive=True)\n",
    "\n",
    "all_baseball_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information from Windows paths\n",
    "\n",
    "On Windows, we need to switch `/` to `\\\\`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1 - Split and get the file name in Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AwardsManagers',\n",
       " 'AwardsPlayers',\n",
       " 'AwardsShareManagers',\n",
       " 'AwardsSharePlayers',\n",
       " 'CollegePlaying',\n",
       " 'HallOfFame',\n",
       " 'Salaries',\n",
       " 'Schools',\n",
       " 'AllstarFull',\n",
       " 'Appearances',\n",
       " 'Batting',\n",
       " 'BattingPost',\n",
       " 'Fielding',\n",
       " 'FieldingOF',\n",
       " 'FieldingOFsplit',\n",
       " 'FieldingPost',\n",
       " 'HomeGames',\n",
       " 'Managers',\n",
       " 'ManagersHalf',\n",
       " 'Parks',\n",
       " 'People',\n",
       " 'Pitching',\n",
       " 'PitchingPost',\n",
       " 'SeriesPost',\n",
       " 'Teams',\n",
       " 'TeamsFranchises',\n",
       " 'TeamsHalf',\n",
       " 'Teams']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_name = lambda p: p.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "[get_file_name(p) for p in all_baseball_csv]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2 - Using a regular expression to extract file name in Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AwardsManagers',\n",
       " 'AwardsPlayers',\n",
       " 'AwardsShareManagers',\n",
       " 'AwardsSharePlayers',\n",
       " 'CollegePlaying',\n",
       " 'HallOfFame',\n",
       " 'Salaries',\n",
       " 'Schools',\n",
       " 'AllstarFull',\n",
       " 'Appearances',\n",
       " 'Batting',\n",
       " 'BattingPost',\n",
       " 'Fielding',\n",
       " 'FieldingOF',\n",
       " 'FieldingOFsplit',\n",
       " 'FieldingPost',\n",
       " 'HomeGames',\n",
       " 'Managers',\n",
       " 'ManagersHalf',\n",
       " 'Parks',\n",
       " 'People',\n",
       " 'Pitching',\n",
       " 'PitchingPost',\n",
       " 'SeriesPost',\n",
       " 'Teams',\n",
       " 'TeamsFranchises',\n",
       " 'TeamsHalf',\n",
       " 'Teams']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = re.compile(r'./data\\\\baseballdatabank-2023.1\\\\[a-z]+\\\\([a-zA-Z]+).csv')\n",
    "\n",
    "get_file_names = lambda paths: [_match.group(1) for p in paths if (_match := file_name.match(p))]\n",
    "\n",
    "get_file_names(all_baseball_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `polars` built-in `glob`\n",
    "\n",
    "* `pl.read_csv( ..., glob=True)` is default,\n",
    "* Will search for all files when given a wildcard/optional/class, and\n",
    "* UNION the resulting tables.\n",
    "\n",
    "**Note.** All information in the file name is lost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th><th>Salesperson</th><th>Compact</th><th>Sedan</th><th>SUV</th><th>Truck</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;Ann&quot;</td><td>22</td><td>18</td><td>15</td><td>12</td></tr><tr><td>1</td><td>&quot;Bob&quot;</td><td>19</td><td>12</td><td>17</td><td>20</td></tr><tr><td>2</td><td>&quot;Yolanda&quot;</td><td>19</td><td>8</td><td>32</td><td>15</td></tr><tr><td>3</td><td>&quot;Xerxes&quot;</td><td>12</td><td>23</td><td>18</td><td>9</td></tr><tr><td>0</td><td>&quot;Ann&quot;</td><td>22</td><td>18</td><td>15</td><td>12</td></tr><tr><td>1</td><td>&quot;Bob&quot;</td><td>20</td><td>14</td><td>6</td><td>24</td></tr><tr><td>2</td><td>&quot;Yolanda&quot;</td><td>19</td><td>10</td><td>28</td><td>17</td></tr><tr><td>3</td><td>&quot;Xerxes&quot;</td><td>11</td><td>27</td><td>17</td><td>9</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 6)\n",
       "┌─────┬─────────────┬─────────┬───────┬─────┬───────┐\n",
       "│     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck │\n",
       "│ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   │\n",
       "│ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   │\n",
       "╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╡\n",
       "│ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       "│ 1   ┆ Bob         ┆ 19      ┆ 12    ┆ 17  ┆ 20    │\n",
       "│ 2   ┆ Yolanda     ┆ 19      ┆ 8     ┆ 32  ┆ 15    │\n",
       "│ 3   ┆ Xerxes      ┆ 12      ┆ 23    ┆ 18  ┆ 9     │\n",
       "│ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       "│ 1   ┆ Bob         ┆ 20      ┆ 14    ┆ 6   ┆ 24    │\n",
       "│ 2   ┆ Yolanda     ┆ 19      ┆ 10    ┆ 28  ┆ 17    │\n",
       "│ 3   ┆ Xerxes      ┆ 11      ┆ 27    ┆ 17  ┆ 9     │\n",
       "└─────┴─────────────┴─────────┴───────┴─────┴───────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_files = pl.read_csv('./data/auto_sales_*.csv')\n",
    "sales_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEWARE - Files need to be UNIONABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "schema lengths differ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/baseball/core/*.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/polars/lib/python3.12/site-packages/polars/_utils/deprecation.py:91\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     88\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     89\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     90\u001b[0m     )\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/polars/lib/python3.12/site-packages/polars/_utils/deprecation.py:91\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     88\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     89\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     90\u001b[0m     )\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/polars/lib/python3.12/site-packages/polars/_utils/deprecation.py:91\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     88\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     89\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m     90\u001b[0m     )\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/polars/lib/python3.12/site-packages/polars/io/csv/functions.py:496\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(source, has_header, columns, new_columns, separator, comment_prefix, quote_char, skip_rows, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m prepare_file_arg(\n\u001b[1;32m    490\u001b[0m         source,\n\u001b[1;32m    491\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    495\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m--> 496\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43m_read_csv_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnull_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnull_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8-lossy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m            \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m            \u001b[49m\u001b[43meol_char\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m            \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m            \u001b[49m\u001b[43mglob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_columns:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _update_columns(df, new_columns)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/polars/lib/python3.12/site-packages/polars/io/csv/functions.py:630\u001b[0m, in \u001b[0;36m_read_csv_impl\u001b[0;34m(source, has_header, columns, separator, comment_prefix, quote_char, skip_rows, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[0m\n\u001b[1;32m    604\u001b[0m scan \u001b[38;5;241m=\u001b[39m scan_csv(\n\u001b[1;32m    605\u001b[0m     source,\n\u001b[1;32m    606\u001b[0m     has_header\u001b[38;5;241m=\u001b[39mhas_header,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m     glob\u001b[38;5;241m=\u001b[39mglob,\n\u001b[1;32m    628\u001b[0m )\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_str_sequence(columns, allow_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scan\u001b[38;5;241m.\u001b[39mselect(columns)\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/polars/lib/python3.12/site-packages/polars/lazyframe/frame.py:2027\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mComputeError\u001b[0m: schema lengths differ"
     ]
    }
   ],
   "source": [
    "pl.read_csv('./data/baseball/core/*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store in `dict` or `list`?\n",
    "\n",
    "* Natural sequence/order? $\\rightarrow$ `list`\n",
    "    *  Example: Lakes data and years are a natural sequence\n",
    "* Easier to refer by name? $\\rightarrow$ `dict`\n",
    "    * Baseball files have no order and easier to refer to by name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Using `glob` to read and UNION the sales data\n",
    "\n",
    "Using `glob` with a `list` to automate reading an combining files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - Get the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/auto_sales_apr.csv', './data/auto_sales_may.csv']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "sales_files = glob('./data/auto_sales_*.csv')\n",
    "sales_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - Read the files into a list of data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[shape: (4, 6)\n",
       " ┌─────┬─────────────┬─────────┬───────┬─────┬───────┐\n",
       " │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck │\n",
       " │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   │\n",
       " │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   │\n",
       " ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╡\n",
       " │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       " │ 1   ┆ Bob         ┆ 19      ┆ 12    ┆ 17  ┆ 20    │\n",
       " │ 2   ┆ Yolanda     ┆ 19      ┆ 8     ┆ 32  ┆ 15    │\n",
       " │ 3   ┆ Xerxes      ┆ 12      ┆ 23    ┆ 18  ┆ 9     │\n",
       " └─────┴─────────────┴─────────┴───────┴─────┴───────┘,\n",
       " shape: (4, 6)\n",
       " ┌─────┬─────────────┬─────────┬───────┬─────┬───────┐\n",
       " │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck │\n",
       " │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   │\n",
       " │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   │\n",
       " ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╡\n",
       " │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       " │ 1   ┆ Bob         ┆ 20      ┆ 14    ┆ 6   ┆ 24    │\n",
       " │ 2   ┆ Yolanda     ┆ 19      ┆ 10    ┆ 28  ┆ 17    │\n",
       " │ 3   ┆ Xerxes      ┆ 11      ┆ 27    ┆ 17  ┆ 9     │\n",
       " └─────┴─────────────┴─────────┴───────┴─────┴───────┘]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_by_month = [pl.read_csv(f) for f in sales_files]\n",
    "sales_by_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Inspect each data from with head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[shape: (2, 6)\n",
       " ┌─────┬─────────────┬─────────┬───────┬─────┬───────┐\n",
       " │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck │\n",
       " │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   │\n",
       " │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   │\n",
       " ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╡\n",
       " │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       " │ 1   ┆ Bob         ┆ 19      ┆ 12    ┆ 17  ┆ 20    │\n",
       " └─────┴─────────────┴─────────┴───────┴─────┴───────┘,\n",
       " shape: (2, 6)\n",
       " ┌─────┬─────────────┬─────────┬───────┬─────┬───────┐\n",
       " │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck │\n",
       " │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   │\n",
       " │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   │\n",
       " ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╡\n",
       " │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       " │ 1   ┆ Bob         ┆ 20      ┆ 14    ┆ 6   ┆ 24    │\n",
       " └─────┴─────────────┴─────────┴───────┴─────┴───────┘]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.head(2) for df in sales_by_month]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the `shape`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 6), (4, 6)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.shape for df in sales_by_month]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Pull off the month from the file names with a RegEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "MONTH_RE = re.compile(r'^\\./data/auto_sales_([a-zA-Z_]*)\\.csv$')\n",
    "get_month = lambda p: MONTH_RE.match(p).group(1) if MONTH_RE.match(p) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/auto_sales_apr.csv', './data/auto_sales_may.csv']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_files = glob('./data/auto_sales_*.csv')\n",
    "sales_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apr', 'may']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_names = [get_month(p) for p in sales_files]\n",
    "month_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[shape: (4, 6)\n",
       " ┌─────┬─────────────┬─────────┬───────┬─────┬───────┐\n",
       " │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck │\n",
       " │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   │\n",
       " │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   │\n",
       " ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╡\n",
       " │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       " │ 1   ┆ Bob         ┆ 19      ┆ 12    ┆ 17  ┆ 20    │\n",
       " │ 2   ┆ Yolanda     ┆ 19      ┆ 8     ┆ 32  ┆ 15    │\n",
       " │ 3   ┆ Xerxes      ┆ 12      ┆ 23    ┆ 18  ┆ 9     │\n",
       " └─────┴─────────────┴─────────┴───────┴─────┴───────┘,\n",
       " shape: (4, 6)\n",
       " ┌─────┬─────────────┬─────────┬───────┬─────┬───────┐\n",
       " │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck │\n",
       " │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   │\n",
       " │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   │\n",
       " ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╡\n",
       " │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       " │ 1   ┆ Bob         ┆ 20      ┆ 14    ┆ 6   ┆ 24    │\n",
       " │ 2   ┆ Yolanda     ┆ 19      ┆ 10    ┆ 28  ┆ 17    │\n",
       " │ 3   ┆ Xerxes      ┆ 11      ┆ 27    ┆ 17  ┆ 9     │\n",
       " └─────┴─────────────┴─────────┴───────┴─────┴───────┘]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_dfs = [pl.read_csv(f) for f in sales_files]\n",
    "\n",
    "sales_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine month and tables in one `list` comprehension\n",
    "\n",
    "Note that we will need the month name later, so we are storing it in a `tuple` with the data frame for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apr',\n",
       "  shape: (4, 6)\n",
       "  ┌─────┬─────────────┬─────────┬───────┬─────┬───────┐\n",
       "  │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck │\n",
       "  │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   │\n",
       "  │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   │\n",
       "  ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╡\n",
       "  │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       "  │ 1   ┆ Bob         ┆ 19      ┆ 12    ┆ 17  ┆ 20    │\n",
       "  │ 2   ┆ Yolanda     ┆ 19      ┆ 8     ┆ 32  ┆ 15    │\n",
       "  │ 3   ┆ Xerxes      ┆ 12      ┆ 23    ┆ 18  ┆ 9     │\n",
       "  └─────┴─────────────┴─────────┴───────┴─────┴───────┘),\n",
       " ('may',\n",
       "  shape: (4, 6)\n",
       "  ┌─────┬─────────────┬─────────┬───────┬─────┬───────┐\n",
       "  │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck │\n",
       "  │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   │\n",
       "  │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   │\n",
       "  ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╡\n",
       "  │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    │\n",
       "  │ 1   ┆ Bob         ┆ 20      ┆ 14    ┆ 6   ┆ 24    │\n",
       "  │ 2   ┆ Yolanda     ┆ 19      ┆ 10    ┆ 28  ┆ 17    │\n",
       "  │ 3   ┆ Xerxes      ┆ 11      ┆ 27    ┆ 17  ┆ 9     │\n",
       "  └─────┴─────────────┴─────────┴───────┴─────┴───────┘)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_by_month = [(get_month(f), pl.read_csv(f)) for f in sales_files]\n",
    "\n",
    "sales_by_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Add a month column to each file\n",
    "\n",
    "Notice that we need to put the `polars` dot-chain *inside* the `list` comprehension to allow access to the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_files_with_month = [(df\n",
    "                          .with_columns(month = pl.lit(mon))\n",
    "                         )\n",
    "                         for mon, df in sales_by_month\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[shape: (2, 7)\n",
       " ┌─────┬─────────────┬─────────┬───────┬─────┬───────┬───────┐\n",
       " │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck ┆ month │\n",
       " │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   ┆ ---   │\n",
       " │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   ┆ str   │\n",
       " ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╪═══════╡\n",
       " │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    ┆ apr   │\n",
       " │ 1   ┆ Bob         ┆ 19      ┆ 12    ┆ 17  ┆ 20    ┆ apr   │\n",
       " └─────┴─────────────┴─────────┴───────┴─────┴───────┴───────┘,\n",
       " shape: (2, 7)\n",
       " ┌─────┬─────────────┬─────────┬───────┬─────┬───────┬───────┐\n",
       " │     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck ┆ month │\n",
       " │ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   ┆ ---   │\n",
       " │ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   ┆ str   │\n",
       " ╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╪═══════╡\n",
       " │ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    ┆ may   │\n",
       " │ 1   ┆ Bob         ┆ 20      ┆ 14    ┆ 6   ┆ 24    ┆ may   │\n",
       " └─────┴─────────────┴─────────┴───────┴─────┴───────┴───────┘]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.head(2) for df in sale_files_with_month]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 - Combine the files using `pl.concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th><th>Salesperson</th><th>Compact</th><th>Sedan</th><th>SUV</th><th>Truck</th><th>month</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Ann&quot;</td><td>22</td><td>18</td><td>15</td><td>12</td><td>&quot;apr&quot;</td></tr><tr><td>1</td><td>&quot;Bob&quot;</td><td>19</td><td>12</td><td>17</td><td>20</td><td>&quot;apr&quot;</td></tr><tr><td>2</td><td>&quot;Yolanda&quot;</td><td>19</td><td>8</td><td>32</td><td>15</td><td>&quot;apr&quot;</td></tr><tr><td>3</td><td>&quot;Xerxes&quot;</td><td>12</td><td>23</td><td>18</td><td>9</td><td>&quot;apr&quot;</td></tr><tr><td>0</td><td>&quot;Ann&quot;</td><td>22</td><td>18</td><td>15</td><td>12</td><td>&quot;may&quot;</td></tr><tr><td>1</td><td>&quot;Bob&quot;</td><td>20</td><td>14</td><td>6</td><td>24</td><td>&quot;may&quot;</td></tr><tr><td>2</td><td>&quot;Yolanda&quot;</td><td>19</td><td>10</td><td>28</td><td>17</td><td>&quot;may&quot;</td></tr><tr><td>3</td><td>&quot;Xerxes&quot;</td><td>11</td><td>27</td><td>17</td><td>9</td><td>&quot;may&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 7)\n",
       "┌─────┬─────────────┬─────────┬───────┬─────┬───────┬───────┐\n",
       "│     ┆ Salesperson ┆ Compact ┆ Sedan ┆ SUV ┆ Truck ┆ month │\n",
       "│ --- ┆ ---         ┆ ---     ┆ ---   ┆ --- ┆ ---   ┆ ---   │\n",
       "│ i64 ┆ str         ┆ i64     ┆ i64   ┆ i64 ┆ i64   ┆ str   │\n",
       "╞═════╪═════════════╪═════════╪═══════╪═════╪═══════╪═══════╡\n",
       "│ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    ┆ apr   │\n",
       "│ 1   ┆ Bob         ┆ 19      ┆ 12    ┆ 17  ┆ 20    ┆ apr   │\n",
       "│ 2   ┆ Yolanda     ┆ 19      ┆ 8     ┆ 32  ┆ 15    ┆ apr   │\n",
       "│ 3   ┆ Xerxes      ┆ 12      ┆ 23    ┆ 18  ┆ 9     ┆ apr   │\n",
       "│ 0   ┆ Ann         ┆ 22      ┆ 18    ┆ 15  ┆ 12    ┆ may   │\n",
       "│ 1   ┆ Bob         ┆ 20      ┆ 14    ┆ 6   ┆ 24    ┆ may   │\n",
       "│ 2   ┆ Yolanda     ┆ 19      ┆ 10    ┆ 28  ┆ 17    ┆ may   │\n",
       "│ 3   ┆ Xerxes      ┆ 11      ┆ 27    ┆ 17  ┆ 9     ┆ may   │\n",
       "└─────┴─────────────┴─────────┴───────┴─────┴───────┴───────┘"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_files = pl.concat(sale_files_with_month)\n",
    "combined_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Exercise 3.1</font>\n",
    "\n",
    "In the data folder, you will find 6 files that contain a sample 100,000 rows from the uber data for the month apr14-sep14.  Perform the following tasks:\n",
    "\n",
    "1. Use `glob` to get all 6 file paths.\n",
    "2. Use a regular expression to create a `lambda` function that pulls the month from the files.\n",
    "3. Read the 6 data frames into a `list` of `tuples` containing the month name corresponding data frame.\n",
    "4. Add the month column each data frame using a pipe inside of a comprehension.\n",
    "5. Use `pd.concat` to combine these 6 data frames into one combined `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/19/2014 16:49:00</td>\n",
       "      <td>40.7568</td>\n",
       "      <td>-73.9701</td>\n",
       "      <td>B02682</td>\n",
       "      <td>jun14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/12/2014 21:25:00</td>\n",
       "      <td>40.6463</td>\n",
       "      <td>-73.7768</td>\n",
       "      <td>B02598</td>\n",
       "      <td>jun14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/15/2014 22:23:00</td>\n",
       "      <td>40.7205</td>\n",
       "      <td>-73.9575</td>\n",
       "      <td>B02512</td>\n",
       "      <td>jun14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/14/2014 20:34:00</td>\n",
       "      <td>40.7639</td>\n",
       "      <td>-73.9624</td>\n",
       "      <td>B02617</td>\n",
       "      <td>jun14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/13/2014 14:36:00</td>\n",
       "      <td>40.7665</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>B02598</td>\n",
       "      <td>jun14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>7/9/2014 7:17:00</td>\n",
       "      <td>40.7329</td>\n",
       "      <td>-73.9794</td>\n",
       "      <td>B02617</td>\n",
       "      <td>jul14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>7/24/2014 13:34:00</td>\n",
       "      <td>40.6713</td>\n",
       "      <td>-73.9846</td>\n",
       "      <td>B02682</td>\n",
       "      <td>jul14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>7/3/2014 10:06:00</td>\n",
       "      <td>40.7623</td>\n",
       "      <td>-73.9660</td>\n",
       "      <td>B02598</td>\n",
       "      <td>jul14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>7/8/2014 22:21:00</td>\n",
       "      <td>40.7670</td>\n",
       "      <td>-73.9171</td>\n",
       "      <td>B02617</td>\n",
       "      <td>jul14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>7/14/2014 17:01:00</td>\n",
       "      <td>40.7331</td>\n",
       "      <td>-73.9948</td>\n",
       "      <td>B02682</td>\n",
       "      <td>jul14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date/Time      Lat      Lon    Base  month\n",
       "0       6/19/2014 16:49:00  40.7568 -73.9701  B02682  jun14\n",
       "1       6/12/2014 21:25:00  40.6463 -73.7768  B02598  jun14\n",
       "2       6/15/2014 22:23:00  40.7205 -73.9575  B02512  jun14\n",
       "3       6/14/2014 20:34:00  40.7639 -73.9624  B02617  jun14\n",
       "4       6/13/2014 14:36:00  40.7665 -73.9667  B02598  jun14\n",
       "...                    ...      ...      ...     ...    ...\n",
       "599995    7/9/2014 7:17:00  40.7329 -73.9794  B02617  jul14\n",
       "599996  7/24/2014 13:34:00  40.6713 -73.9846  B02682  jul14\n",
       "599997   7/3/2014 10:06:00  40.7623 -73.9660  B02598  jul14\n",
       "599998   7/8/2014 22:21:00  40.7670 -73.9171  B02617  jul14\n",
       "599999  7/14/2014 17:01:00  40.7331 -73.9948  B02682  jul14\n",
       "\n",
       "[600000 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "file_paths = glob.glob('./data/*.csv')\n",
    "\n",
    "uber_file_paths = [file for file in file_paths if re.search(r'uber-raw-data-(apr14|may14|jun14|jul14|aug14|sep14)', file)]\n",
    "\n",
    "def extract_month(file_path):\n",
    "    match = re.search(r'apr14|may14|jun14|jul14|aug14|sep14', file_path)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        raise ValueError(f\"No month found in file path: {file_path}\")\n",
    "\n",
    "dataframes = [(extract_month(file), pd.read_csv(file)) for file in uber_file_paths]\n",
    "\n",
    "dataframes = [(month, df.pipe(lambda x: x.assign(month=month))) for month, df in dataframes]\n",
    "\n",
    "combined_df = pd.concat([df for _, df in dataframes], ignore_index=True)\n",
    "\n",
    "combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.12.4"
=======
   "version": "3.12.3"
>>>>>>> 74fafc1f9bcfce0d3fca0451484db2a593f394c4
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
